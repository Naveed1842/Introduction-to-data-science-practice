{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Regression Trees \n",
    "[decision tree in scikit learn](\"http://scikit-learn.org/stable/modules/tree.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a regression tree by hand\n",
    "1.  Read the data into a Pandas DataFrame\n",
    "2.  Explore the data by sorting, ploting, or split-apply-combine ()aka group_by \n",
    "3.  Decided which feature is the most important predictor, and use that to create your firist spliting rule. \n",
    "\n",
    " - Only binary splits are allowed.\n",
    "\n",
    "4.  After making your first split, spit your DataFrame into two parts, and then explore each part to figure out what other splits to make. \n",
    "5.  Stop makring splits once your are convinced that it strikes a good balance between underfitting and overfitting \n",
    "\n",
    " - Your goal is to build a model that generalizes well\n",
    " - You are allowed to split on the same variable multiple times! \n",
    "\n",
    "6.  Draw your tree, labeling the leaves with the mean price for the observations in that region.\n",
    "\n",
    " - Make sure nothing is backwards: You follow the **left branch** if the rule is true, and the **right branch** if the rule is false.\n",
    "\n",
    "# How does a computer build a regression tree?\n",
    "**Ideal approach**: Consider every possible partition of the feature space(computationally infeasible)\n",
    "**Good enough** approach: recursive binary splitting\n",
    "1. Begin at the top of the tree\n",
    "2. For **every feature**, examine **every possible cutpoint**, and choose the feature and cutpoint such that the resulting tree has the lowest possible mean squared error(MSE). Make that split\n",
    "3. Examine the two resulting regions, and again make a **single split** (in one of the regions) to minimize the MSE\n",
    "4. Keep repeating step 3 until a **stopping criterion** is met:\n",
    "- maximum tree depth\n",
    "- minimum number of observations in a leaf\n",
    "## Demo: Choosing the ideal cutpoint for a given feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/justmarkham/DAT8/master/data/vehicles_train.csv\"\n",
    "train = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>miles</th>\n",
       "      <th>doors</th>\n",
       "      <th>vtype</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22000</td>\n",
       "      <td>2012</td>\n",
       "      <td>13000</td>\n",
       "      <td>2</td>\n",
       "      <td>car</td>\n",
       "      <td>6571.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14000</td>\n",
       "      <td>2010</td>\n",
       "      <td>30000</td>\n",
       "      <td>2</td>\n",
       "      <td>car</td>\n",
       "      <td>6571.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13000</td>\n",
       "      <td>2010</td>\n",
       "      <td>73500</td>\n",
       "      <td>4</td>\n",
       "      <td>car</td>\n",
       "      <td>6571.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9500</td>\n",
       "      <td>2009</td>\n",
       "      <td>78000</td>\n",
       "      <td>4</td>\n",
       "      <td>car</td>\n",
       "      <td>6571.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9000</td>\n",
       "      <td>2007</td>\n",
       "      <td>47000</td>\n",
       "      <td>4</td>\n",
       "      <td>car</td>\n",
       "      <td>6571.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4000</td>\n",
       "      <td>2006</td>\n",
       "      <td>124000</td>\n",
       "      <td>2</td>\n",
       "      <td>car</td>\n",
       "      <td>6571.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3000</td>\n",
       "      <td>2004</td>\n",
       "      <td>177000</td>\n",
       "      <td>4</td>\n",
       "      <td>car</td>\n",
       "      <td>6571.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000</td>\n",
       "      <td>2004</td>\n",
       "      <td>209000</td>\n",
       "      <td>4</td>\n",
       "      <td>truck</td>\n",
       "      <td>6571.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3000</td>\n",
       "      <td>2003</td>\n",
       "      <td>138000</td>\n",
       "      <td>2</td>\n",
       "      <td>car</td>\n",
       "      <td>6571.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1900</td>\n",
       "      <td>2003</td>\n",
       "      <td>160000</td>\n",
       "      <td>4</td>\n",
       "      <td>car</td>\n",
       "      <td>6571.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2500</td>\n",
       "      <td>2003</td>\n",
       "      <td>190000</td>\n",
       "      <td>2</td>\n",
       "      <td>truck</td>\n",
       "      <td>6571.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5000</td>\n",
       "      <td>2001</td>\n",
       "      <td>62000</td>\n",
       "      <td>4</td>\n",
       "      <td>car</td>\n",
       "      <td>6571.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1800</td>\n",
       "      <td>1999</td>\n",
       "      <td>163000</td>\n",
       "      <td>2</td>\n",
       "      <td>truck</td>\n",
       "      <td>6571.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1300</td>\n",
       "      <td>1997</td>\n",
       "      <td>138000</td>\n",
       "      <td>4</td>\n",
       "      <td>car</td>\n",
       "      <td>6571.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price  year   miles  doors  vtype   prediction\n",
       "0   22000  2012   13000      2    car  6571.428571\n",
       "1   14000  2010   30000      2    car  6571.428571\n",
       "2   13000  2010   73500      4    car  6571.428571\n",
       "3    9500  2009   78000      4    car  6571.428571\n",
       "4    9000  2007   47000      4    car  6571.428571\n",
       "5    4000  2006  124000      2    car  6571.428571\n",
       "6    3000  2004  177000      4    car  6571.428571\n",
       "7    2000  2004  209000      4  truck  6571.428571\n",
       "8    3000  2003  138000      2    car  6571.428571\n",
       "9    1900  2003  160000      4    car  6571.428571\n",
       "10   2500  2003  190000      2  truck  6571.428571\n",
       "11   5000  2001   62000      4    car  6571.428571\n",
       "12   1800  1999  163000      2  truck  6571.428571\n",
       "13   1300  1997  138000      4    car  6571.428571"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['prediction'] = train.price.mean()\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5936.9819859959835"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "np.sqrt(metrics.mean_squared_error(train.price, train.prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mileage_split(miles):\n",
    "    lower_mileage_price = train[train.miles < miles].price.mean()\n",
    "    higher_mileage_price = train[train.miles >= miles].price.mean()\n",
    "    train['prediction']=np.where(train.miles < miles, lower_mileage_price, higher_mileage_price)\n",
    "    return np.sqrt(metrics.mean_squared_error(train.price, train.prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3984.0917425414564"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mileage_split(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3530.1465300762688"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mileage_split(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mileage_range=range(train.miles.min(), train.miles.max())\n",
    "RMSE = [mileage_split(miles) for miles in mileage_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize']=(6,4)\n",
    "plt.rcParams['font.size']=14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10ae59a90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbIAAAEZCAYAAADyqKAxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ae33588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mileage_range, RMSE)\n",
    "plt.xlabel('Mileage cutpoint')\n",
    "plt.ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recap**: Before every split, this process is repeated for every feature, and the feature and cutpoint that produces the lowest MSE is chosen. \n",
    "\n",
    "## Building a regression tree in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['vtype'] = train.vtype.map({\"car\":0, \"truck\":1})\n",
    "feature_cols = ['year', 'miles', 'doors', 'vtype']\n",
    "X = train[feature_cols]\n",
    "y = train.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "           splitter='best')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "treereg = DecisionTreeRegressor(random_state=1)\n",
    "treereg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3107.1428571428573"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "scores = cross_val_score(treereg, X, y, cv=14, scoring='mean_squared_error')\n",
    "np.mean(np.sqrt(-scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-64000000., -64000000., -12250000., -12250000., -16000000.,\n",
       "       -25000000.,  -1000000.,  -1000000.,  -2890000.,  -1210000.,\n",
       "         -250000., -16000000.,   -250000.,  -2890000.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What happens when we grow a tree too deep?\n",
    "The **training error** continues to go down as the tree size increase(due to overfitting), but the lowest **cross-validation error** occurs for a tree with 3 leaves. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning a regression tree\n",
    "Let's try to reduce the RMSE by tuning the **max_depth** parameter:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4050.1443001442999"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treereg = DecisionTreeRegressor(max_depth = 1, random_state=1)\n",
    "scores = cross_val_score(treereg, X,y, cv=14, scoring=\"mean_squared_error\")\n",
    "np.mean(np.sqrt(-scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_depth_range = range(1,8)\n",
    "RMSE_scores=[]\n",
    "for depth in max_depth_range:\n",
    "    treereg = DecisionTreeRegressor(max_depth=depth, random_state=1)\n",
    "    MSE_scores = cross_val_score(treereg, X,y, cv=14, scoring=\"mean_squared_error\")\n",
    "    RMSE_scores.append(np.mean(np.sqrt(-MSE_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10b118668>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEQCAYAAACjnUNyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM7O8OGGYmVlenDDMzCwv/x8u3jsRlHkMNgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109fb31d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(max_depth_range, RMSE_scores)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=3, max_features=None,\n",
       "           max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "           splitter='best')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treereg = DecisionTreeRegressor(max_depth=3, random_state=1)\n",
    "treereg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>year</td>\n",
       "      <td>0.798744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>miles</td>\n",
       "      <td>0.201256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doors</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vtype</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature  importance\n",
       "0    year    0.798744\n",
       "1   miles    0.201256\n",
       "2   doors    0.000000\n",
       "3   vtype    0.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'feature':feature_cols, \"importance\":treereg.feature_importances_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a tree diagram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(treereg, out_file='tree.dot', feature_names=feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Making prediction for the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>miles</th>\n",
       "      <th>doors</th>\n",
       "      <th>vtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000</td>\n",
       "      <td>2003</td>\n",
       "      <td>130000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6000</td>\n",
       "      <td>2005</td>\n",
       "      <td>82500</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12000</td>\n",
       "      <td>2010</td>\n",
       "      <td>60000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  year   miles  doors  vtype\n",
       "0   3000  2003  130000      4      1\n",
       "1   6000  2005   82500      4      0\n",
       "2  12000  2010   60000      2      0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/vehicles_test.csv'\n",
    "test = pd.read_csv(url)\n",
    "test['vtype'] = test.vtype.map({'car':0, 'truck':1})\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4000.,   5000.,  13500.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test[feature_cols]\n",
    "y_test = test.price\n",
    "y_pred = treereg.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1190.2380714238084"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Classification trees\n",
    "\n",
    "## Comparing regression trees and classifcation tree\n",
    "**regression trees**                     | **classification trees**\n",
    "------------------                       | --------------------\n",
    "predict a continuous response            | predict a categorical response\n",
    "predict using mean response of each leaf | predict using most commonly occuring class of each leaf\n",
    "splits are chosen to minimize MSE | splits are chosen to minimize Gini index (discuss below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting criteria for classification trees\n",
    "Common options for the splitting criteria: \n",
    "- **classification error rate**: fraction of training observations in a region that don't belong to the most common class\n",
    "- **Gini index:** measure of total variance across classes in a gregion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of classification error rate\n",
    "Pretend we are predicting whether someone buys an iPhone or an Android:\n",
    "- At a particular node, there are **25 observations**(phone buyers), of whom **10 bought iPhone and 15 bought Androids**. \n",
    "- Since the majority class is **Android,** that's our prediction for all 25 observations, and thus the classification error rate is **10/25=40%**. \n",
    "\n",
    "Our goal is making splits is to **reduce the classification error reate** Let's try splitting on gender:\n",
    "\n",
    "- **Males**: 2 iPhones and 12 Androids, thus the predicted class is Android\n",
    "- **Female**: 8 iPhones and 3 Androids, thus the predicted class is iPhone\n",
    "- Classification error rate after this split would be 5/25=20%\n",
    "\n",
    "Compare that with a split on age:\n",
    "- **30 or younger**: 4 iPhones and 8 Androids, thus the predicted cclass is Android\n",
    "- **31 or older**: 6 iPhones and 7 Androids, thus the predicted class is Android\n",
    "- Classification error rate after this split would be 10/25 = 40%\n",
    "\n",
    "This decision tree algorithm will try **every possible split across all features**, and choose the split that **reduces the error rate the most**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of Gini index\n",
    "Calculate the Gini index before making a split: \n",
    "- The **maximum value** of the Gini index is 0.5, and occurs when the classes are prefectly balanced in a node. \n",
    "- The **minimum value** of the Gini index is 0, and occurs when there is only one class represented in a node. \n",
    "- A node with a lower Gini index is said to be more \"pure\". \n",
    "Evaluating the split on **gender** using Gini index: \n",
    "                                Males: 1−(2/14)^2−(12/14)^2=0.24\n",
    "                                Females: 1−(8/11)^2−(3/11)^2=0.40\n",
    "                                Weighted Average: 0.24(14/25)+0.40(11/25)=0.3\n",
    "Again, the decision tree algorithm will try **every possible split**, and will choose the split that **reduces the Gini index(and thus the \"node purity\") the most**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing classification error rate and Gini index\n",
    "- Gini index is generally preferred because it will make splits that **increase node purity**, even if that split does not change the classification error rate. \n",
    "- Node purity is important because we're interested in the **class proportions** in each region, since that's how we calculate the **predicted probability** of each class. \n",
    "- scikit-learn's default splitting criteria for classification is Gini index.\n",
    "\n",
    "Note: There is another common spliting criteria called cross-entropy. It is numerically similar to Gini index, but slower to complete, thus it's not as popular as Gini index. (check my own note to see how entropy works)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a classification tree in scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url=\"https://raw.githubusercontent.com/justmarkham/DAT8/master/data/titanic.csv\"\n",
    "titanic=pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic['Sex']=titanic.Sex.map({'female':0, 'male':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic.Age.fillna(titanic.Age.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embarked_dummies=pd.get_dummies(titanic.Embarked,prefix='Embarked')\n",
    "embarked_dummies.drop(embarked_dummies.columns[0],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic = pd.concat([titanic, embarked_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry    1  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin Embarked  Embarked_Q  Embarked_S  \n",
       "0         A/5 21171   7.2500   NaN        S         0.0         1.0  \n",
       "1          PC 17599  71.2833   C85        C         0.0         0.0  \n",
       "2  STON/O2. 3101282   7.9250   NaN        S         0.0         1.0  \n",
       "3            113803  53.1000  C123        S         0.0         1.0  \n",
       "4            373450   8.0500   NaN        S         0.0         1.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols = ['Pclass', 'Sex', 'Age','Embarked_Q','Embarked_S']\n",
    "X = titanic[feature_cols]\n",
    "y = titanic.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=1, splitter='best')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "treefit = DecisionTreeClassifier(max_depth=3, random_state=1)\n",
    "treefit.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.externals.six import StringIO\n",
    "import pydot \n",
    "tree.export_graphviz(treefit, out_file='tree.dot',feature_names=feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>important</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.242664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.655584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.064494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>0.037258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  important\n",
       "0      Pclass   0.242664\n",
       "1         Sex   0.655584\n",
       "2         Age   0.064494\n",
       "3  Embarked_Q   0.000000\n",
       "4  Embarked_S   0.037258"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'feature':feature_cols, 'important':treefit.feature_importances_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Comparing decision trees with other model\n",
    "### Advantages of decision trees:\n",
    "- Can be used for regression or classification\n",
    "- Can be displayed graphically\n",
    "- Highly interpretable\n",
    "- Can be specified as a series of rules, and more closely approximate human decision-making than other models\n",
    "- Prediction is fast\n",
    "- Feature don't need scaling\n",
    "- Automatically learns feature interactions\n",
    "- Tends to ignore irrelevant features\n",
    "- Non-parametric(will outperform linear models if relationship between features and response is highly non-linear)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
